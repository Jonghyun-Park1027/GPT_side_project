{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877a3455",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import chromadb python package. Please install it with `pip install chromadb`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ppjjh\\anaconda3\\envs\\GPT2\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:83\u001b[39m, in \u001b[36mChroma.__init__\u001b[39m\u001b[34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'chromadb'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# 3) 임베딩 & 벡터스토어\u001b[39;00m\n\u001b[32m     26\u001b[39m embeddings = OpenAIEmbeddings()\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m vectordb = Chroma.from_documents(chunks, embedding=embeddings)\n\u001b[32m     28\u001b[39m retriever = vectordb.as_retriever(search_kwargs={\u001b[33m\"\u001b[39m\u001b[33mk\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m4\u001b[39m})\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# 4) StuffDocuments 체인 (단순 이어붙이기)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ppjjh\\anaconda3\\envs\\GPT2\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:887\u001b[39m, in \u001b[36mChroma.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m    885\u001b[39m texts = [doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m    886\u001b[39m metadatas = [doc.metadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.from_texts(\n\u001b[32m    888\u001b[39m     texts=texts,\n\u001b[32m    889\u001b[39m     embedding=embedding,\n\u001b[32m    890\u001b[39m     metadatas=metadatas,\n\u001b[32m    891\u001b[39m     ids=ids,\n\u001b[32m    892\u001b[39m     collection_name=collection_name,\n\u001b[32m    893\u001b[39m     persist_directory=persist_directory,\n\u001b[32m    894\u001b[39m     client_settings=client_settings,\n\u001b[32m    895\u001b[39m     client=client,\n\u001b[32m    896\u001b[39m     collection_metadata=collection_metadata,\n\u001b[32m    897\u001b[39m     **kwargs,\n\u001b[32m    898\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ppjjh\\anaconda3\\envs\\GPT2\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:817\u001b[39m, in \u001b[36mChroma.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m    784\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    785\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_texts\u001b[39m(\n\u001b[32m    786\u001b[39m     \u001b[38;5;28mcls\u001b[39m: Type[Chroma],\n\u001b[32m   (...)\u001b[39m\u001b[32m    796\u001b[39m     **kwargs: Any,\n\u001b[32m    797\u001b[39m ) -> Chroma:\n\u001b[32m    798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[32m    799\u001b[39m \n\u001b[32m    800\u001b[39m \u001b[33;03m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    815\u001b[39m \u001b[33;03m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[32m    816\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m817\u001b[39m     chroma_collection = \u001b[38;5;28mcls\u001b[39m(\n\u001b[32m    818\u001b[39m         collection_name=collection_name,\n\u001b[32m    819\u001b[39m         embedding_function=embedding,\n\u001b[32m    820\u001b[39m         persist_directory=persist_directory,\n\u001b[32m    821\u001b[39m         client_settings=client_settings,\n\u001b[32m    822\u001b[39m         client=client,\n\u001b[32m    823\u001b[39m         collection_metadata=collection_metadata,\n\u001b[32m    824\u001b[39m         **kwargs,\n\u001b[32m    825\u001b[39m     )\n\u001b[32m    826\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    827\u001b[39m         ids = [\u001b[38;5;28mstr\u001b[39m(uuid.uuid4()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ppjjh\\anaconda3\\envs\\GPT2\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:222\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    220\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    221\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ppjjh\\anaconda3\\envs\\GPT2\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:86\u001b[39m, in \u001b[36mChroma.__init__\u001b[39m\u001b[34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[39m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     87\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import chromadb python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     88\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install chromadb`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     89\u001b[39m     )\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     92\u001b[39m     \u001b[38;5;28mself\u001b[39m._client_settings = client_settings\n",
      "\u001b[31mImportError\u001b[39m: Could not import chromadb python package. Please install it with `pip install chromadb`."
     ]
    }
   ],
   "source": [
    "# --- 0. 의존 패키지 (미설치 시) ---\n",
    "# pip install langchain-openai langchain-community chromadb tiktoken\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# 1) 원본 문서 로드\n",
    "RAW_URL = (\n",
    "    \"https://gist.githubusercontent.com/serranoarevalo/\"\n",
    "    \"5acf755c2b8d83f1707ef266b82ea223/raw/\"\n",
    ")\n",
    "loader = WebBaseLoader(RAW_URL)\n",
    "docs = loader.load()  # → Document() 리스트\n",
    "\n",
    "# 2) 청크 분할\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "# 3) 임베딩 & 벡터스토어\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(chunks, embedding=embeddings)\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# 4) StuffDocuments 체인 (단순 이어붙이기)\n",
    "doc_prompt = PromptTemplate(\n",
    "    input_variables=[\"page_content\"],\n",
    "    template=\"{page_content}\",\n",
    ")\n",
    "combine_docs_chain = StuffDocumentsChain(\n",
    "    llm=ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0),\n",
    "    document_prompt=doc_prompt,\n",
    "    document_variable_name=\"context\",\n",
    ")\n",
    "\n",
    "# 5) ConversationBufferMemory 부여한 RAG QA\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "rag_qa = RetrievalQA(\n",
    "    retriever=retriever,\n",
    "    combine_documents_chain=combine_docs_chain,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# 6) 질의 실행\n",
    "questions = [\n",
    "    \"Aaronson 은 유죄인가요?\",\n",
    "    \"그가 테이블에 어떤 메시지를 썼나요?\",\n",
    "    \"Julia 는 누구인가요?\",\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    result = rag_qa.invoke({\"query\": q})\n",
    "    print(f\"Q: {q}\\nA: {result['result']}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
