{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f28febe2a60cd4de",
   "metadata": {},
   "source": [
    "# Serialization and Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340eeda0109ffad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:10:51.530681Z",
     "start_time": "2025-07-06T06:10:51.527678Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts.pipeline import PipelinePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "270be497eaa9d2e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T05:40:46.378401Z",
     "start_time": "2025-07-06T05:40:46.373175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\4_study\\\\GPT'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7484e434da7200f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:23:59.194151Z",
     "start_time": "2025-07-06T06:23:59.191147Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(\"./day5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1c16988f7a96abd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:24:03.646202Z",
     "start_time": "2025-07-06T06:24:03.642700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\4_study\\\\GPT\\\\day5'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "57e9ff780f0b2791",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:24:08.378627Z",
     "start_time": "2025-07-06T06:24:08.375242Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = load_prompt(\"./prompt.yaml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a169e2b4416005ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T05:54:26.515154Z",
     "start_time": "2025-07-06T05:54:26.511651Z"
    }
   },
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name=\"gpt-4o-2024-08-06\", streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "# temperature Îì± ÏòµÏÖòÎèÑ ÏßÄÏ†ï Í∞ÄÎä•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89960b3e639a4d6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T05:54:27.323132Z",
     "start_time": "2025-07-06T05:54:27.319616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of germany'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(country = \"germany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71cb7f1027292ca9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:11:26.814053Z",
     "start_time": "2025-07-06T06:11:26.810450Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a role playing assistant.\n",
    "    And you are impersonating a {character}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    This is an example of how you talk:\n",
    "\n",
    "    Human: {example_question}\n",
    "    You: {example_answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Start now!\n",
    "\n",
    "    Human: {question}\n",
    "    You:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {intro}\n",
    "                                     \n",
    "    {example}\n",
    "                              \n",
    "    {start}\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0f26aea21fb02be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:11:27.006031Z",
     "start_time": "2025-07-06T06:11:27.003031Z"
    }
   },
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    (\"intro\", intro),\n",
    "    (\"example\", example),\n",
    "    (\"start\",start)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f49e59fd522a686",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:11:51.183384Z",
     "start_time": "2025-07-06T06:11:51.179286Z"
    }
   },
   "outputs": [],
   "source": [
    "full_prompt = PipelinePromptTemplate(final_prompt = final,\n",
    "                                     pipeline_prompts = prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb596027f9a3f0c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:15:03.293847Z",
     "start_time": "2025-07-06T06:15:03.290828Z"
    }
   },
   "outputs": [],
   "source": [
    "chain = full_prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8452afa7fd4d170e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:15:33.045376Z",
     "start_time": "2025-07-06T06:15:31.444195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrrg! Me favorite grub be a hearty serving of salt pork and hardtack, washed down with a mug of grog! Just the kind of fare to keep a pirate's belly full on the high seas, arrr! üçñüè¥‚Äç‚ò†Ô∏è"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Arrrg! Me favorite grub be a hearty serving of salt pork and hardtack, washed down with a mug of grog! Just the kind of fare to keep a pirate's belly full on the high seas, arrr! üçñüè¥\\u200d‚ò†Ô∏è\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'service_tier': 'default'}, id='run--0459fee6-4b9a-447e-bcea-70b78ac045ca-0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chain.invoke({\n",
    "        \"character\" : \"Pirate\",\n",
    "    \"example_question\" : \"What is your location?\",\n",
    "    \"example_answer\":\"Arrrg! That is a secret!! argg\",\n",
    "    \"question\" : \"What is your fav food?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf636f29f78384bb",
   "metadata": {},
   "source": [
    "# Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5a64efdbb6c1243",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:22:12.151376Z",
     "start_time": "2025-07-06T06:22:12.146867Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.globals import set_llm_cache, set_debug\n",
    "from langchain.cache import InMemoryCache, SQLiteCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "928ad4b43b8eb3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:24:15.551733Z",
     "start_time": "2025-07-06T06:24:15.506948Z"
    }
   },
   "outputs": [],
   "source": [
    "set_llm_cache(SQLiteCache(\"cache.db\"))\n",
    "# set_debug(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a55f2343be3c7992",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:24:15.681452Z",
     "start_time": "2025-07-06T06:24:15.677513Z"
    }
   },
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name=\"gpt-4o-2024-08-06\",\n",
    "                  # streaming=True, \n",
    "                  # callbacks=[StreamingStdOutCallbackHandler()                          ]\n",
    "                  )\n",
    "# temperature Îì± ÏòµÏÖòÎèÑ ÏßÄÏ†ï Í∞ÄÎä•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "934a07fda66c1c24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:24:23.212895Z",
     "start_time": "2025-07-06T06:24:15.836648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: How do you make italian pasta\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [7.37s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Making Italian pasta from scratch is a rewarding and relatively simple process. Here‚Äôs a basic guide to making fresh pasta dough:\\n\\n### Ingredients:\\n- 2 cups (250g) all-purpose flour (or tipo \\\"00\\\" flour for a more authentic texture)\\n- 3 large eggs\\n- A pinch of salt\\n- A tablespoon of olive oil (optional)\\n\\n### Equipment:\\n- Mixing bowl\\n- Fork or dough whisk\\n- Rolling pin or pasta machine\\n- Sharp knife or pasta cutter\\n- Baking sheets\\n- Clean kitchen towel or plastic wrap\\n- Flour for dusting\\n\\n### Instructions:\\n\\n1. **Prepare the Dough:**\\n   - On a clean work surface, pour the flour into a mound. Make a well in the center of the flour and crack the eggs into it. If using a bowl, place the flour in and create a well in the middle.\\n   - Add salt and olive oil to the eggs (if using).\\n   - Using a fork, gently beat the eggs, gradually incorporating the flour starting from the inner rim of the well. Continue until the mixture is too stiff to mix with a fork.\\n\\n2. **Knead the Dough:**\\n   - Bring the dough together with your hands, incorporating the remaining flour.\\n   - Knead the dough by pressing it with the heel of your hand, folding it over, and turning it repeatedly for about 8-10 minutes until it‚Äôs smooth and elastic. The dough should be pliable and slightly sticky.\\n   - Wrap the dough in plastic wrap or cover it with a towel and let it rest at room temperature for at least 30 minutes. This allows the gluten to relax, making it easier to roll out.\\n\\n3. **Roll Out the Dough:**\\n   - Divide the rested dough into quarters. Keep the pieces you aren‚Äôt currently using covered to prevent them from drying out.\\n   - Dust a working surface and rolling pin (or pasta machine) with flour. Flatten a piece of dough slightly with your hands, then roll it out using a rolling pin or pass it through the pasta machine, starting with the thickest setting.\\n   - Continue rolling it through the machine, gradually reducing the thickness settings, until the pasta reaches your desired thickness. If using a rolling pin, roll from the center outwards, rotating the dough frequently.\\n\\n4. **Cut the Pasta:**\\n   - Once rolled out, dust the pasta sheet lightly with flour to prevent sticking.\\n   - Roll the sheet into a log shape and slice it into strips of your desired width (e.g., fettuccine, tagliatelle).\\n   - Unroll the strips and lay them flat or in small nests on a floured surface or baking sheet.\\n\\n5. **Cook the Pasta:**\\n   - Bring a large pot of salted water to a boil.\\n   - Add the pasta and cook for 2-4 minutes until al dente. Fresh pasta cooks more quickly than dried pasta.\\n   - Drain the pasta and toss it with your favorite sauce or simply with olive oil, Parmesan, and fresh herbs.\\n\\n### Tips:\\n- If the dough feels too dry while kneading, wet your hands lightly and continue to knead. If it's too sticky, incorporate a little more flour as needed.\\n- You can use semolina flour for dusting, which gives the pasta a nice texture and prevents sticking.\\n- Experiment with adding spinach, tomato paste, or herbs to the dough for flavored and colored variations.\\n\\nEnjoy your homemade Italian pasta!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Making Italian pasta from scratch is a rewarding and relatively simple process. Here‚Äôs a basic guide to making fresh pasta dough:\\n\\n### Ingredients:\\n- 2 cups (250g) all-purpose flour (or tipo \\\"00\\\" flour for a more authentic texture)\\n- 3 large eggs\\n- A pinch of salt\\n- A tablespoon of olive oil (optional)\\n\\n### Equipment:\\n- Mixing bowl\\n- Fork or dough whisk\\n- Rolling pin or pasta machine\\n- Sharp knife or pasta cutter\\n- Baking sheets\\n- Clean kitchen towel or plastic wrap\\n- Flour for dusting\\n\\n### Instructions:\\n\\n1. **Prepare the Dough:**\\n   - On a clean work surface, pour the flour into a mound. Make a well in the center of the flour and crack the eggs into it. If using a bowl, place the flour in and create a well in the middle.\\n   - Add salt and olive oil to the eggs (if using).\\n   - Using a fork, gently beat the eggs, gradually incorporating the flour starting from the inner rim of the well. Continue until the mixture is too stiff to mix with a fork.\\n\\n2. **Knead the Dough:**\\n   - Bring the dough together with your hands, incorporating the remaining flour.\\n   - Knead the dough by pressing it with the heel of your hand, folding it over, and turning it repeatedly for about 8-10 minutes until it‚Äôs smooth and elastic. The dough should be pliable and slightly sticky.\\n   - Wrap the dough in plastic wrap or cover it with a towel and let it rest at room temperature for at least 30 minutes. This allows the gluten to relax, making it easier to roll out.\\n\\n3. **Roll Out the Dough:**\\n   - Divide the rested dough into quarters. Keep the pieces you aren‚Äôt currently using covered to prevent them from drying out.\\n   - Dust a working surface and rolling pin (or pasta machine) with flour. Flatten a piece of dough slightly with your hands, then roll it out using a rolling pin or pass it through the pasta machine, starting with the thickest setting.\\n   - Continue rolling it through the machine, gradually reducing the thickness settings, until the pasta reaches your desired thickness. If using a rolling pin, roll from the center outwards, rotating the dough frequently.\\n\\n4. **Cut the Pasta:**\\n   - Once rolled out, dust the pasta sheet lightly with flour to prevent sticking.\\n   - Roll the sheet into a log shape and slice it into strips of your desired width (e.g., fettuccine, tagliatelle).\\n   - Unroll the strips and lay them flat or in small nests on a floured surface or baking sheet.\\n\\n5. **Cook the Pasta:**\\n   - Bring a large pot of salted water to a boil.\\n   - Add the pasta and cook for 2-4 minutes until al dente. Fresh pasta cooks more quickly than dried pasta.\\n   - Drain the pasta and toss it with your favorite sauce or simply with olive oil, Parmesan, and fresh herbs.\\n\\n### Tips:\\n- If the dough feels too dry while kneading, wet your hands lightly and continue to knead. If it's too sticky, incorporate a little more flour as needed.\\n- You can use semolina flour for dusting, which gives the pasta a nice texture and prevents sticking.\\n- Experiment with adding spinach, tomato paste, or herbs to the dough for flavored and colored variations.\\n\\nEnjoy your homemade Italian pasta!\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 704,\n",
      "                \"prompt_tokens\": 13,\n",
      "                \"total_tokens\": 717,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_07871e2ad8\",\n",
      "              \"id\": \"chatcmpl-BqD5LVWZrdyGBoVCJIkEAETvWYWd0\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--fa4a29ce-50cf-4b5d-a3a5-078d8612941d-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 13,\n",
      "              \"output_tokens\": 704,\n",
      "              \"total_tokens\": 717,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 704,\n",
      "      \"prompt_tokens\": 13,\n",
      "      \"total_tokens\": 717,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"system_fingerprint\": \"fp_07871e2ad8\",\n",
      "    \"id\": \"chatcmpl-BqD5LVWZrdyGBoVCJIkEAETvWYWd0\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Making Italian pasta from scratch is a rewarding and relatively simple process. Here‚Äôs a basic guide to making fresh pasta dough:\\n\\n### Ingredients:\\n- 2 cups (250g) all-purpose flour (or tipo \"00\" flour for a more authentic texture)\\n- 3 large eggs\\n- A pinch of salt\\n- A tablespoon of olive oil (optional)\\n\\n### Equipment:\\n- Mixing bowl\\n- Fork or dough whisk\\n- Rolling pin or pasta machine\\n- Sharp knife or pasta cutter\\n- Baking sheets\\n- Clean kitchen towel or plastic wrap\\n- Flour for dusting\\n\\n### Instructions:\\n\\n1. **Prepare the Dough:**\\n   - On a clean work surface, pour the flour into a mound. Make a well in the center of the flour and crack the eggs into it. If using a bowl, place the flour in and create a well in the middle.\\n   - Add salt and olive oil to the eggs (if using).\\n   - Using a fork, gently beat the eggs, gradually incorporating the flour starting from the inner rim of the well. Continue until the mixture is too stiff to mix with a fork.\\n\\n2. **Knead the Dough:**\\n   - Bring the dough together with your hands, incorporating the remaining flour.\\n   - Knead the dough by pressing it with the heel of your hand, folding it over, and turning it repeatedly for about 8-10 minutes until it‚Äôs smooth and elastic. The dough should be pliable and slightly sticky.\\n   - Wrap the dough in plastic wrap or cover it with a towel and let it rest at room temperature for at least 30 minutes. This allows the gluten to relax, making it easier to roll out.\\n\\n3. **Roll Out the Dough:**\\n   - Divide the rested dough into quarters. Keep the pieces you aren‚Äôt currently using covered to prevent them from drying out.\\n   - Dust a working surface and rolling pin (or pasta machine) with flour. Flatten a piece of dough slightly with your hands, then roll it out using a rolling pin or pass it through the pasta machine, starting with the thickest setting.\\n   - Continue rolling it through the machine, gradually reducing the thickness settings, until the pasta reaches your desired thickness. If using a rolling pin, roll from the center outwards, rotating the dough frequently.\\n\\n4. **Cut the Pasta:**\\n   - Once rolled out, dust the pasta sheet lightly with flour to prevent sticking.\\n   - Roll the sheet into a log shape and slice it into strips of your desired width (e.g., fettuccine, tagliatelle).\\n   - Unroll the strips and lay them flat or in small nests on a floured surface or baking sheet.\\n\\n5. **Cook the Pasta:**\\n   - Bring a large pot of salted water to a boil.\\n   - Add the pasta and cook for 2-4 minutes until al dente. Fresh pasta cooks more quickly than dried pasta.\\n   - Drain the pasta and toss it with your favorite sauce or simply with olive oil, Parmesan, and fresh herbs.\\n\\n### Tips:\\n- If the dough feels too dry while kneading, wet your hands lightly and continue to knead. If it\\'s too sticky, incorporate a little more flour as needed.\\n- You can use semolina flour for dusting, which gives the pasta a nice texture and prevents sticking.\\n- Experiment with adding spinach, tomato paste, or herbs to the dough for flavored and colored variations.\\n\\nEnjoy your homemade Italian pasta!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 704, 'prompt_tokens': 13, 'total_tokens': 717, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-BqD5LVWZrdyGBoVCJIkEAETvWYWd0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--fa4a29ce-50cf-4b5d-a3a5-078d8612941d-0', usage_metadata={'input_tokens': 13, 'output_tokens': 704, 'total_tokens': 717, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(\"How do you make italian pasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c4743fb1a66c83aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:24:25.439806Z",
     "start_time": "2025-07-06T06:24:25.432298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: How do you make italian pasta\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [3ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Making Italian pasta from scratch is a rewarding and relatively simple process. Here‚Äôs a basic guide to making fresh pasta dough:\\n\\n### Ingredients:\\n- 2 cups (250g) all-purpose flour (or tipo \\\"00\\\" flour for a more authentic texture)\\n- 3 large eggs\\n- A pinch of salt\\n- A tablespoon of olive oil (optional)\\n\\n### Equipment:\\n- Mixing bowl\\n- Fork or dough whisk\\n- Rolling pin or pasta machine\\n- Sharp knife or pasta cutter\\n- Baking sheets\\n- Clean kitchen towel or plastic wrap\\n- Flour for dusting\\n\\n### Instructions:\\n\\n1. **Prepare the Dough:**\\n   - On a clean work surface, pour the flour into a mound. Make a well in the center of the flour and crack the eggs into it. If using a bowl, place the flour in and create a well in the middle.\\n   - Add salt and olive oil to the eggs (if using).\\n   - Using a fork, gently beat the eggs, gradually incorporating the flour starting from the inner rim of the well. Continue until the mixture is too stiff to mix with a fork.\\n\\n2. **Knead the Dough:**\\n   - Bring the dough together with your hands, incorporating the remaining flour.\\n   - Knead the dough by pressing it with the heel of your hand, folding it over, and turning it repeatedly for about 8-10 minutes until it‚Äôs smooth and elastic. The dough should be pliable and slightly sticky.\\n   - Wrap the dough in plastic wrap or cover it with a towel and let it rest at room temperature for at least 30 minutes. This allows the gluten to relax, making it easier to roll out.\\n\\n3. **Roll Out the Dough:**\\n   - Divide the rested dough into quarters. Keep the pieces you aren‚Äôt currently using covered to prevent them from drying out.\\n   - Dust a working surface and rolling pin (or pasta machine) with flour. Flatten a piece of dough slightly with your hands, then roll it out using a rolling pin or pass it through the pasta machine, starting with the thickest setting.\\n   - Continue rolling it through the machine, gradually reducing the thickness settings, until the pasta reaches your desired thickness. If using a rolling pin, roll from the center outwards, rotating the dough frequently.\\n\\n4. **Cut the Pasta:**\\n   - Once rolled out, dust the pasta sheet lightly with flour to prevent sticking.\\n   - Roll the sheet into a log shape and slice it into strips of your desired width (e.g., fettuccine, tagliatelle).\\n   - Unroll the strips and lay them flat or in small nests on a floured surface or baking sheet.\\n\\n5. **Cook the Pasta:**\\n   - Bring a large pot of salted water to a boil.\\n   - Add the pasta and cook for 2-4 minutes until al dente. Fresh pasta cooks more quickly than dried pasta.\\n   - Drain the pasta and toss it with your favorite sauce or simply with olive oil, Parmesan, and fresh herbs.\\n\\n### Tips:\\n- If the dough feels too dry while kneading, wet your hands lightly and continue to knead. If it's too sticky, incorporate a little more flour as needed.\\n- You can use semolina flour for dusting, which gives the pasta a nice texture and prevents sticking.\\n- Experiment with adding spinach, tomato paste, or herbs to the dough for flavored and colored variations.\\n\\nEnjoy your homemade Italian pasta!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Making Italian pasta from scratch is a rewarding and relatively simple process. Here‚Äôs a basic guide to making fresh pasta dough:\\n\\n### Ingredients:\\n- 2 cups (250g) all-purpose flour (or tipo \\\"00\\\" flour for a more authentic texture)\\n- 3 large eggs\\n- A pinch of salt\\n- A tablespoon of olive oil (optional)\\n\\n### Equipment:\\n- Mixing bowl\\n- Fork or dough whisk\\n- Rolling pin or pasta machine\\n- Sharp knife or pasta cutter\\n- Baking sheets\\n- Clean kitchen towel or plastic wrap\\n- Flour for dusting\\n\\n### Instructions:\\n\\n1. **Prepare the Dough:**\\n   - On a clean work surface, pour the flour into a mound. Make a well in the center of the flour and crack the eggs into it. If using a bowl, place the flour in and create a well in the middle.\\n   - Add salt and olive oil to the eggs (if using).\\n   - Using a fork, gently beat the eggs, gradually incorporating the flour starting from the inner rim of the well. Continue until the mixture is too stiff to mix with a fork.\\n\\n2. **Knead the Dough:**\\n   - Bring the dough together with your hands, incorporating the remaining flour.\\n   - Knead the dough by pressing it with the heel of your hand, folding it over, and turning it repeatedly for about 8-10 minutes until it‚Äôs smooth and elastic. The dough should be pliable and slightly sticky.\\n   - Wrap the dough in plastic wrap or cover it with a towel and let it rest at room temperature for at least 30 minutes. This allows the gluten to relax, making it easier to roll out.\\n\\n3. **Roll Out the Dough:**\\n   - Divide the rested dough into quarters. Keep the pieces you aren‚Äôt currently using covered to prevent them from drying out.\\n   - Dust a working surface and rolling pin (or pasta machine) with flour. Flatten a piece of dough slightly with your hands, then roll it out using a rolling pin or pass it through the pasta machine, starting with the thickest setting.\\n   - Continue rolling it through the machine, gradually reducing the thickness settings, until the pasta reaches your desired thickness. If using a rolling pin, roll from the center outwards, rotating the dough frequently.\\n\\n4. **Cut the Pasta:**\\n   - Once rolled out, dust the pasta sheet lightly with flour to prevent sticking.\\n   - Roll the sheet into a log shape and slice it into strips of your desired width (e.g., fettuccine, tagliatelle).\\n   - Unroll the strips and lay them flat or in small nests on a floured surface or baking sheet.\\n\\n5. **Cook the Pasta:**\\n   - Bring a large pot of salted water to a boil.\\n   - Add the pasta and cook for 2-4 minutes until al dente. Fresh pasta cooks more quickly than dried pasta.\\n   - Drain the pasta and toss it with your favorite sauce or simply with olive oil, Parmesan, and fresh herbs.\\n\\n### Tips:\\n- If the dough feels too dry while kneading, wet your hands lightly and continue to knead. If it's too sticky, incorporate a little more flour as needed.\\n- You can use semolina flour for dusting, which gives the pasta a nice texture and prevents sticking.\\n- Experiment with adding spinach, tomato paste, or herbs to the dough for flavored and colored variations.\\n\\nEnjoy your homemade Italian pasta!\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 704,\n",
      "                \"prompt_tokens\": 13,\n",
      "                \"total_tokens\": 717,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_07871e2ad8\",\n",
      "              \"id\": \"chatcmpl-BqD5LVWZrdyGBoVCJIkEAETvWYWd0\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--fa4a29ce-50cf-4b5d-a3a5-078d8612941d-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 13,\n",
      "              \"output_tokens\": 704,\n",
      "              \"total_tokens\": 717,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Making Italian pasta from scratch is a rewarding and relatively simple process. Here‚Äôs a basic guide to making fresh pasta dough:\\n\\n### Ingredients:\\n- 2 cups (250g) all-purpose flour (or tipo \"00\" flour for a more authentic texture)\\n- 3 large eggs\\n- A pinch of salt\\n- A tablespoon of olive oil (optional)\\n\\n### Equipment:\\n- Mixing bowl\\n- Fork or dough whisk\\n- Rolling pin or pasta machine\\n- Sharp knife or pasta cutter\\n- Baking sheets\\n- Clean kitchen towel or plastic wrap\\n- Flour for dusting\\n\\n### Instructions:\\n\\n1. **Prepare the Dough:**\\n   - On a clean work surface, pour the flour into a mound. Make a well in the center of the flour and crack the eggs into it. If using a bowl, place the flour in and create a well in the middle.\\n   - Add salt and olive oil to the eggs (if using).\\n   - Using a fork, gently beat the eggs, gradually incorporating the flour starting from the inner rim of the well. Continue until the mixture is too stiff to mix with a fork.\\n\\n2. **Knead the Dough:**\\n   - Bring the dough together with your hands, incorporating the remaining flour.\\n   - Knead the dough by pressing it with the heel of your hand, folding it over, and turning it repeatedly for about 8-10 minutes until it‚Äôs smooth and elastic. The dough should be pliable and slightly sticky.\\n   - Wrap the dough in plastic wrap or cover it with a towel and let it rest at room temperature for at least 30 minutes. This allows the gluten to relax, making it easier to roll out.\\n\\n3. **Roll Out the Dough:**\\n   - Divide the rested dough into quarters. Keep the pieces you aren‚Äôt currently using covered to prevent them from drying out.\\n   - Dust a working surface and rolling pin (or pasta machine) with flour. Flatten a piece of dough slightly with your hands, then roll it out using a rolling pin or pass it through the pasta machine, starting with the thickest setting.\\n   - Continue rolling it through the machine, gradually reducing the thickness settings, until the pasta reaches your desired thickness. If using a rolling pin, roll from the center outwards, rotating the dough frequently.\\n\\n4. **Cut the Pasta:**\\n   - Once rolled out, dust the pasta sheet lightly with flour to prevent sticking.\\n   - Roll the sheet into a log shape and slice it into strips of your desired width (e.g., fettuccine, tagliatelle).\\n   - Unroll the strips and lay them flat or in small nests on a floured surface or baking sheet.\\n\\n5. **Cook the Pasta:**\\n   - Bring a large pot of salted water to a boil.\\n   - Add the pasta and cook for 2-4 minutes until al dente. Fresh pasta cooks more quickly than dried pasta.\\n   - Drain the pasta and toss it with your favorite sauce or simply with olive oil, Parmesan, and fresh herbs.\\n\\n### Tips:\\n- If the dough feels too dry while kneading, wet your hands lightly and continue to knead. If it\\'s too sticky, incorporate a little more flour as needed.\\n- You can use semolina flour for dusting, which gives the pasta a nice texture and prevents sticking.\\n- Experiment with adding spinach, tomato paste, or herbs to the dough for flavored and colored variations.\\n\\nEnjoy your homemade Italian pasta!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 704, 'prompt_tokens': 13, 'total_tokens': 717, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-BqD5LVWZrdyGBoVCJIkEAETvWYWd0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--fa4a29ce-50cf-4b5d-a3a5-078d8612941d-0', usage_metadata={'input_tokens': 13, 'output_tokens': 704, 'total_tokens': 717, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(\"How do you make italian pasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712d6f29081b4814",
   "metadata": {},
   "source": [
    "# Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb67b92093d88d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:30:35.420793Z",
     "start_time": "2025-07-06T06:30:35.417286Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24d69a74d630335d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:30:35.604818Z",
     "start_time": "2025-07-06T06:30:35.601478Z"
    }
   },
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name=\"gpt-4o-2024-08-06\",\n",
    "                  # streaming=True, \n",
    "                  # callbacks=[StreamingStdOutCallbackHandler()                          ]\n",
    "                  )\n",
    "# temperature Îì± ÏòµÏÖòÎèÑ ÏßÄÏ†ï Í∞ÄÎä•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "495781be216db437",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:30:35.814413Z",
     "start_time": "2025-07-06T06:30:35.792826Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_openai_callback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# get_openai_callbackÏùÄ Ìï®ÏàòÏù¥Í∏∞ ÎïåÎ¨∏Ïóê, context managerÎ°ú ÏÇ¨Ïö©ÌïòÎ†§Î©¥ ()Î•º Î∂ôÏó¨Ïïº Ìï©ÎãàÎã§.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_openai_callback() \u001b[38;5;28;01mas\u001b[39;00m usage:\n\u001b[32m      3\u001b[39m     a = chat.invoke(\u001b[33m\"\u001b[39m\u001b[33mWhat is the recipe for soju\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m     b = chat.invoke(\u001b[33m\"\u001b[39m\u001b[33mWhat is the recipe for bread\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'get_openai_callback' is not defined"
     ]
    }
   ],
   "source": [
    "# get_openai_callbackÏùÄ Ìï®ÏàòÏù¥Í∏∞ ÎïåÎ¨∏Ïóê, context managerÎ°ú ÏÇ¨Ïö©ÌïòÎ†§Î©¥ ()Î•º Î∂ôÏó¨Ïïº Ìï©ÎãàÎã§.\n",
    "with get_openai_callback() as usage:\n",
    "    a = chat.invoke(\"What is the recipe for soju\")\n",
    "    b = chat.invoke(\"What is the recipe for bread\")\n",
    "    print(a,b,\"\\n\")\n",
    "    print(usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cbf3104dcab0791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.llms.loading import load_llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9aa8ce1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ppjjh\\anaconda3\\envs\\GPT2\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3667: UserWarning: WARNING! max_token is not default parameter.\n",
      "                max_token was transferred to model_kwargs.\n",
      "                Please confirm that max_token is what you intended.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "chat_2 = OpenAI(\n",
    "    temperature = 0.1,\n",
    "    max_token=450,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b5cd880",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_2.save(file_path=\"model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "136ed5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ppjjh\\anaconda3\\envs\\GPT2\\Lib\\site-packages\\langchain_community\\llms\\loading.py:55: UserWarning: WARNING! max_token is not default parameter.\n",
      "                max_token was transferred to model_kwargs.\n",
      "                Please confirm that max_token is what you intended.\n",
      "  return load_llm_from_config(config, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "chat_2 = load_llm(\"model.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4daa41",
   "metadata": {},
   "source": [
    "# Conversation Buffer memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bf4ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16bb760",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory =ConversationBufferMemory(return_messages=True) # TrueÌïòÎ©¥ chatÎ™®Îç∏Ïóê Ïì∏Ïàò ÏûàÍ≤å Î≥ÄÌï®Ìï®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ae1cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\":\"Hi!\"}, {\"outputs\":\"How are you\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b91a0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='How are you', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23834098",
   "metadata": {},
   "source": [
    "# Conversation Buffer Window memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2de8e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89bc9c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ppjjh\\AppData\\Local\\Temp\\ipykernel_25676\\1055178638.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    return_messages=True,\n",
    "    k = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a4de494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": str(input)}, {\"output\":str(output)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27a20129",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad9abffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(2,2)\n",
    "add_message(3,3)\n",
    "add_message(4,4)\n",
    "add_message(5,5)\n",
    "add_message(6,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58df2796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='3', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='5', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='5', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='6', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='6', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfed4dcc",
   "metadata": {},
   "source": [
    "# Conversation Summary Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9759593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b63f60e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d77b5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ppjjh\\AppData\\Local\\Temp\\ipykernel_12540\\1952740995.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(llm=llm)\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationSummaryMemory(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85e67ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": str(input)}, {\"output\":str(output)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94415981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history():\n",
    "    return memory.aload_memory_variables({})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09789b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"Hi I'm Park, I live in south korea\", \"Wow that is so cool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59ebe4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"South korea is so pretty\", \"I wish I could go!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e30cadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'The human introduces themselves as Park and mentions they live in South Korea, commenting that South Korea is so pretty. The AI responds with enthusiasm, noting that it is cool and expressing a desire to visit.'}\n"
     ]
    }
   ],
   "source": [
    "history = memory.load_memory_variables({})\n",
    "# print(get_history())\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481e0119",
   "metadata": {},
   "source": [
    "# Conversation Summary Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b36eebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2170bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm = llm,\n",
    "    max_token_limit = 150,\n",
    "    return_messages=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b07efffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": str(input)}, {\"output\":str(output)})\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "248edc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"Hi I'm Park, I live in south korea\", \"Wow that is so cool!\")\n",
    "add_message(\"South korea is so pretty\", \"I wish I could go!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4e86705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm Park, I live in south korea\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Wow that is so cool!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='South korea is so pretty', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I wish I could go!!!', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0d12293",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"How far is Korea from argentina?\", \"Idon't know! Super far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c079077f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm Park, I live in south korea\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Wow that is so cool!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='South korea is so pretty', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I wish I could go!!!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='How far is Korea from argentina?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Idon't know! Super far!\", additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f92c405",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"How far is Brazil from argentina?\", \"Idon't know! Super far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db61b075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm Park, I live in south korea\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Wow that is so cool!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='South korea is so pretty', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I wish I could go!!!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='How far is Korea from argentina?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Idon't know! Super far!\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='How far is Brazil from argentina?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Idon't know! Super far!\", additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e397ccf",
   "metadata": {},
   "source": [
    "# conversation KGMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84944633",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import networkx python package. Please install it with `pip install networkx`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ppjjh\\anaconda3\\envs\\GPT2\\Lib\\site-packages\\langchain_community\\graphs\\networkx_graph.py:68\u001b[39m, in \u001b[36mNetworkxEntityGraph.__init__\u001b[39m\u001b[34m(self, graph)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnx\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'networkx'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI, OpenAI\n\u001b[32m      9\u001b[39m llm = ChatOpenAI()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m memory = ConversationKGMemory(\n\u001b[32m     11\u001b[39m     llm = llm,\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# max_token_limit = 150,\u001b[39;00m\n\u001b[32m     13\u001b[39m     return_messages=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_message\u001b[39m(\u001b[38;5;28minput\u001b[39m, output):\n\u001b[32m     16\u001b[39m     memory.save_context({\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28minput\u001b[39m)}, {\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m:\u001b[38;5;28mstr\u001b[39m(output)})\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ppjjh\\anaconda3\\envs\\GPT2\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:222\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    220\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    221\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ppjjh\\anaconda3\\envs\\GPT2\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:222\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    220\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    221\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ppjjh\\anaconda3\\envs\\GPT2\\Lib\\site-packages\\langchain_core\\load\\serializable.py:130\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(*args, **kwargs)\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ppjjh\\anaconda3\\envs\\GPT2\\Lib\\site-packages\\langchain_community\\graphs\\networkx_graph.py:70\u001b[39m, in \u001b[36mNetworkxEntityGraph.__init__\u001b[39m\u001b[34m(self, graph)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnetworkx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnx\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     71\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import networkx python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     72\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install networkx`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m     )\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(graph, nx.DiGraph):\n",
      "\u001b[31mImportError\u001b[39m: Could not import networkx python package. Please install it with `pip install networkx`."
     ]
    }
   ],
   "source": [
    "# networkx Ìå®ÌÇ§ÏßÄÍ∞Ä ÏÑ§ÏπòÎêòÏñ¥ ÏûàÏßÄ ÏïäÏïÑ ConversationKGMemoryÎ•º ÏÇ¨Ïö©Ìï† Ïàò ÏóÜÏäµÎãàÎã§.\n",
    "# ÏïÑÎûò Î™ÖÎ†πÏñ¥Î°ú networkxÎ•º ÏÑ§ÏπòÌïòÏÑ∏Ïöî.\n",
    "# !pip install networkx\n",
    "\n",
    "# ÏÑ§Ïπò ÌõÑ ÏïÑÎûò ÏΩîÎìúÎ•º Ïã§ÌñâÌïòÏÑ∏Ïöî.\n",
    "from langchain.memory import ConversationKGMemory\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "memory = ConversationKGMemory(\n",
    "    llm = llm,\n",
    "    # max_token_limit = 150,\n",
    "    return_messages=True,\n",
    ")\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": str(input)}, {\"output\":str(output)})\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd939e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"Hi I'm Park, I live in south korea\", \"Wow that is so cool!\")\n",
    "add_message(\"South korea is so pretty\", \"I wish I could go!!!\")\n",
    "get_history()\n",
    "add_message(\"How far is Korea from argentina?\", \"Idon't know! Super far!\")\n",
    "get_history()\n",
    "add_message(\"How far is Brazil from argentina?\", \"Idon't know! Super far!\")\n",
    "get_history()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5be220",
   "metadata": {},
   "source": [
    "# Memory on LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35aac595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "457d49c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_lmit = 120,\n",
    "    memory_key = \"chat_history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d82cf939",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a helpful AI talking to a human\n",
    "\n",
    "{chat_history}\n",
    "Human:{question}\n",
    "You :\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc38ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory = memory,\n",
    "    prompt= PromptTemplate.from_template(template),\n",
    "    verbose = True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "762635b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a helpful AI talking to a human\n",
      "\n",
      "Human: My name is Nico\n",
      "AI: Hello Nico! How can I assist you today?\n",
      "Human: I live in seoul\n",
      "AI: That's great to hear! Is there anything specific you would like to know or talk about regarding Seoul?\n",
      "Human: What is my name\n",
      "AI: Your name is Nico.\n",
      "Human:My name is Nico\n",
      "You :\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'My name is Nico',\n",
       " 'chat_history': \"Human: My name is Nico\\nAI: Hello Nico! How can I assist you today?\\nHuman: I live in seoul\\nAI: That's great to hear! Is there anything specific you would like to know or talk about regarding Seoul?\\nHuman: What is my name\\nAI: Your name is Nico.\",\n",
       " 'text': \"That's right, your name is Nico. How can I assist you further, Nico?\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input = \"My name is Nico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16f184e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a helpful AI talking to a human\n",
      "\n",
      "Human: My name is Nico\n",
      "AI: Hello Nico! How can I assist you today?\n",
      "Human:I live in seoul\n",
      "You :\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'I live in seoul',\n",
       " 'chat_history': 'Human: My name is Nico\\nAI: Hello Nico! How can I assist you today?',\n",
       " 'text': \"That's great to hear! Is there anything specific you would like to know or talk about regarding Seoul?\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input = \"I live in seoul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39b8c6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a helpful AI talking to a human\n",
      "\n",
      "Human: My name is Nico\n",
      "AI: Hello Nico! How can I assist you today?\n",
      "Human: I live in seoul\n",
      "AI: That's great to hear! Is there anything specific you would like to know or talk about regarding Seoul?\n",
      "Human:What is my name\n",
      "You :\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is my name',\n",
       " 'chat_history': \"Human: My name is Nico\\nAI: Hello Nico! How can I assist you today?\\nHuman: I live in seoul\\nAI: That's great to hear! Is there anything specific you would like to know or talk about regarding Seoul?\",\n",
       " 'text': 'Your name is Nico.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input = \"What is my name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56c98e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': \"Human: My name is Nico\\nAI: Hello Nico! How can I assist you today?\\nHuman: I live in seoul\\nAI: That's great to hear! Is there anything specific you would like to know or talk about regarding Seoul?\\nHuman: What is my name\\nAI: Your name is Nico.\\nHuman: My name is Nico\\nAI: That's right, your name is Nico. How can I assist you further, Nico?\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d331e",
   "metadata": {},
   "source": [
    "# Chat Based Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "957a3709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0406872",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatOpenAI()\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_lmit = 120,\n",
    "    memory_key = \"chat_history\",\n",
    "    return_messages=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b63a25a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\",\"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8409fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory = memory,\n",
    "    prompt= prompt,\n",
    "    verbose = True,\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6f067cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: My name is Nico\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'My name is Nico',\n",
       " 'chat_history': [HumanMessage(content='My name is Nico', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, Nico! How can I assist you today?', additional_kwargs={}, response_metadata={})],\n",
       " 'text': 'Nice to meet you, Nico! How can I assist you today?'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input = \"My name is Nico\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43ad9582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: My name is Nico\n",
      "AI: Nice to meet you, Nico! How can I assist you today?\n",
      "Human: I live in seoul\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'I live in seoul',\n",
       " 'chat_history': [HumanMessage(content='My name is Nico', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, Nico! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='I live in seoul', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's great! Seoul is a vibrant city with a rich history and culture. Is there anything specific you would like to know about or discuss regarding Seoul?\", additional_kwargs={}, response_metadata={})],\n",
       " 'text': \"That's great! Seoul is a vibrant city with a rich history and culture. Is there anything specific you would like to know about or discuss regarding Seoul?\"}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input = \"I live in seoul\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef89e3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: My name is Nico\n",
      "AI: Nice to meet you, Nico! How can I assist you today?\n",
      "Human: I live in seoul\n",
      "AI: That's great! Seoul is a vibrant city with a rich history and culture. Is there anything specific you would like to know about or discuss regarding Seoul?\n",
      "Human: What is my name\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is my name',\n",
       " 'chat_history': [HumanMessage(content='My name is Nico', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, Nico! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='I live in seoul', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's great! Seoul is a vibrant city with a rich history and culture. Is there anything specific you would like to know about or discuss regarding Seoul?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is my name', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Your name is Nico.', additional_kwargs={}, response_metadata={})],\n",
       " 'text': 'Your name is Nico.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input = \"What is my name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c49b557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='My name is Nico', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, Nico! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='I live in seoul', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's great! Seoul is a vibrant city with a rich history and culture. Is there anything specific you would like to know about or discuss regarding Seoul?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is my name', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Your name is Nico.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fa324e",
   "metadata": {},
   "source": [
    "# LCEL Based Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de5b6fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83729046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatOpenAI()\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_lmit = 120,\n",
    "    memory_key = \"chat_history\",\n",
    "    return_messages=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22d73cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\",\"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "220f576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_memory(input):\n",
    "    print(input)\n",
    "    return memory.load_memory_variables({})[\"chat_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "868facf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# chain = LLMChain(\n",
    "#     llm=llm,\n",
    "#     memory = memory,\n",
    "#     prompt= prompt,\n",
    "#     verbose = True,\n",
    "\n",
    "# )\n",
    "chain = RunnablePassthrough.assign(chat_history=load_memory) | prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f6d87d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain.invoke(input = \"My name is Nico\")\n",
    "# chain.invoke({\n",
    "#     # \"chat_history\": ,\n",
    "#     \"question\" : \"My name is Nico\"\n",
    "# })\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\n",
    "\n",
    "    \"question\" : \"question\"\n",
    "    })\n",
    "    memory.save_context({\"input\":question}, {\"outputs\":result.content})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d8618c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'question'}\n",
      "content='How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 21, 'total_tokens': 28, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BqJCDKQsaEHKIAUYp0vFozOMMN5qz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--d48b3d0a-e42c-4602-8ee8-cced34b9d1ba-0' usage_metadata={'input_tokens': 21, 'output_tokens': 7, 'total_tokens': 28, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Ïù¥Í±∞ Ïôú ÎèôÏûëÏïàÌïòÏßÄ?\n",
    "invoke_chain(\"My name is Nico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "16bcffbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'question'}\n",
      "content=\"Please go ahead and ask your question, Nico. I'm here to help.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 40, 'total_tokens': 56, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BqJCuNiY5bkPr5ikGYD3GFXJjhJJj', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--3d0eb467-eb33-4f1c-b297-ea481de39ba3-0' usage_metadata={'input_tokens': 40, 'output_tokens': 16, 'total_tokens': 56, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# # chain.invoke(input = \"I live in seoul\")\n",
    "# chain.invoke({\n",
    "#     # \"chat_history\": ,\n",
    "#     \"question\" : \"I live in seoul\"\n",
    "# })\n",
    "invoke_chain(\"I live in seoul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "676315f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'question'}\n",
      "content='Of course! What would you like to know or ask about? Feel free to share your question with me.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 234, 'total_tokens': 256, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BqJG640r88ysRB5EZocTPCWOoIiid', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--bd0da4df-3ee9-44eb-bbe9-e198ae3a9397-0' usage_metadata={'input_tokens': 234, 'output_tokens': 22, 'total_tokens': 256, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# # chain.invoke(input = \"What is my name\")\n",
    "# chain.invoke({\n",
    "#     # \"chat_history\": ,\n",
    "#     \"question\" : \"What is my name\"\n",
    "# })\n",
    "invoke_chain(\"yeah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ccfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
