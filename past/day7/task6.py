# app.py
# -------------------------------------------------------------
# Streamlit ê¸°ë°˜ RAG-Lite Chat â€“ íŒŒì¼ ì—…ë¡œë“œ, ì±„íŒ… íˆìŠ¤í† ë¦¬
# -------------------------------------------------------------
import os, tempfile, requests, streamlit as st
from openai import OpenAI

# ---------- ì‚¬ì´ë“œë°” ----------
st.sidebar.title("âš™ï¸ ì„¤ì •")
repo_link = "https://github.com/<your-org-or-id>/<repo>/blob/main/app.py"
st.sidebar.markdown(f"[ğŸ“‚ GitHubì—ì„œ ì†ŒìŠ¤ ë³´ê¸°]({repo_link})")

st.title("ğŸ—‚ï¸ RAG-Lite Chat")

# ---------- API í´ë¼ì´ì–¸íŠ¸ ----------
# setxë¡œ í™˜ê²½ë³€ìˆ˜ì— OPENAI_API_KEYë¥¼ ë¯¸ë¦¬ ë“±ë¡í–ˆìœ¼ë¯€ë¡œ ë³„ë„ ì…ë ¥ ì—†ì´ ì‚¬ìš©
client = OpenAI()

# ---------- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ----------
if "assistant_id" not in st.session_state:
    st.session_state.assistant_id = None
    st.session_state.thread_id = None
    st.session_state.vector_store_id = None
    st.session_state.chat_history = []  # [{role, content}, â€¦]

# ---------- íŒŒì¼ ì—…ë¡œë“œ ----------
uploaded = st.sidebar.file_uploader(
    "ğŸ“ ì§€ì‹ íŒŒì¼ ì—…ë¡œë“œ (.txt, .pdf, .docx ë“±)",
    type=["txt", "pdf", "docx"],
    help="ë¬¸ì„œë¥¼ ì˜¬ë¦¬ë©´ ìë™ìœ¼ë¡œ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë§Œë“¤ê³  ì—°ê²°í•©ë‹ˆë‹¤.",
)


def bootstrap_assistant(file_path: str, file_name: str):
    """íŒŒì¼ì„ OpenAIì— ì˜¬ë¦¬ê³  Assistant/Thread/VectorStoreë¥¼ í•œ ë²ˆì— ì´ˆê¸°í™”"""
    # 1) íŒŒì¼ ì—…ë¡œë“œ
    file_obj = client.files.create(file=open(file_path, "rb"), purpose="assistants")
    # 2) ë²¡í„°ìŠ¤í† ì–´ ìƒì„± + íŒŒì¼ ë“±ë¡
    vs = client.vector_stores.create(name=f"rag_vs_{file_name}")
    client.vector_stores.files.create_and_poll(
        vector_store_id=vs.id, file_id=file_obj.id
    )
    # 3) Assistant ìƒì„±
    assistant = client.beta.assistants.create(
        name="RAG-Lite",
        instructions="ê·¼ê±° ë¬¸ì¥ì„ ì¸ìš©í•´ í•œêµ­ì–´ë¡œ ê°„ë‹¨íˆ ë‹µí•˜ì„¸ìš”.",
        model="gpt-4o-mini",
        tools=[{"type": "file_search"}],
        tool_resources={"file_search": {"vector_store_ids": [vs.id]}},
    )
    # 4) Thread ìƒì„±
    thread = client.beta.threads.create()

    # ì„¸ì…˜ ìƒíƒœ ì €ì¥
    st.session_state.assistant_id = assistant.id
    st.session_state.thread_id = thread.id
    st.session_state.vector_store_id = vs.id
    st.session_state.chat_history.clear()


# ì²˜ìŒ ì ‘ì† ì‹œ íŒŒì¼ ì—†ìœ¼ë©´ Gist ì›ë¬¸ ê¸°ë³¸ ë¡œë”©(ì˜µì…˜)
DEFAULT_GIST = "https://gist.githubusercontent.com/serranoarevalo/5acf755c2b8d83f1707ef266b82ea223/raw/"
if st.session_state.assistant_id is None:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".txt") as tmp:
        txt = requests.get(DEFAULT_GIST, timeout=30).text
        tmp.write(txt.encode("utf-8"))
        tmp_path = tmp.name
    bootstrap_assistant(tmp_path, "aaronson_gist.txt")

# ìƒˆ íŒŒì¼ ì—…ë¡œë“œ ì‹œ ì¬ì´ˆê¸°í™”
if uploaded is not None:
    with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{uploaded.name}") as tmp:
        tmp.write(uploaded.read())
        up_path = tmp.name
    bootstrap_assistant(up_path, uploaded.name)
    st.success("ğŸ”„ ìƒˆ ë¬¸ì„œë¡œ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ê°±ì‹ í–ˆìŠµë‹ˆë‹¤!")

# ---------- ì±„íŒ… UI ----------
# ê³¼ê±° ëŒ€í™” ë Œë”ë§
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì…ë ¥ì°½
user_query = st.chat_input("ë¬¸ì„œ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•´ ë³´ì„¸ìš”â€¦")
if user_query:
    # 1) í™”ë©´ì— ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    st.session_state.chat_history.append({"role": "user", "content": user_query})
    with st.chat_message("user"):
        st.markdown(user_query)

    # 2) OpenAI Threadì— ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    client.beta.threads.messages.create(
        thread_id=st.session_state.thread_id,
        role="user",
        content=user_query,
    )

    # 3) Assistant ì‹¤í–‰
    run = client.beta.threads.runs.create_and_poll(
        thread_id=st.session_state.thread_id,
        assistant_id=st.session_state.assistant_id,
    )

    # 4) ìµœì‹  Assistant ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
    msgs = client.beta.threads.messages.list(thread_id=st.session_state.thread_id).data
    assistant_msgs = [m for m in msgs if m.role == "assistant"]
    if assistant_msgs:
        answer = assistant_msgs[0].content[0].text.value
        st.session_state.chat_history.append({"role": "assistant", "content": answer})
        with st.chat_message("assistant"):
            st.markdown(answer)

# ---------- í•˜ë‹¨ ì£¼ì„ ----------
st.markdown("---")
st.caption("â“’ 2025 RAG-Lite Streamlit ë°ëª¨")
